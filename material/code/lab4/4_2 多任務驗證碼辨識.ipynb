{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 字元集\n",
    "CHAR_SET = [str(i) for i in range(10)]\n",
    "CHAR_SET_LEN = len(CHAR_SET)\n",
    "# 訓練集大小\n",
    "TRAIN_NUM = 4000\n",
    "# 批次大小\n",
    "BATCH_SIZE = 100\n",
    "# 迭代次數\n",
    "TOTAL_STEPS = 4000\n",
    "# tfrecord文件\n",
    "TFRECORD_FILE = 'captcha/train.tfrecord'\n",
    "# 初始學習率\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFRecordDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_decode(serial_exmp):\n",
    "    features = tf.parse_single_example(serial_exmp,\n",
    "                                       features={\n",
    "                                           'image': tf.FixedLenFeature([], tf.string),\n",
    "                                           'label0': tf.FixedLenFeature([], tf.int64),\n",
    "                                           'label1': tf.FixedLenFeature([], tf.int64),\n",
    "                                           'label2': tf.FixedLenFeature([], tf.int64),\n",
    "                                           'label3': tf.FixedLenFeature([], tf.int64)\n",
    "                                       })\n",
    "    image = tf.decode_raw(features['image'], tf.uint8)\n",
    "    image = tf.reshape(image,[224, 224])\n",
    "    image = tf.cast(image, tf.float32) / 255.0    # 0 to 1\n",
    "    image = tf.subtract(image, 0.5)               # -0.5 to 0.5\n",
    "    image = tf.multiply(image, 2.0)               # -1 to 1\n",
    "\n",
    "    label0 = tf.cast(features['label0'], tf.int32)\n",
    "    label1 = tf.cast(features['label1'], tf.int32)\n",
    "    label2 = tf.cast(features['label2'], tf.int32)\n",
    "    label3 = tf.cast(features['label3'], tf.int32)\n",
    "    return image, label0, label1, label2, label3\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(TFRECORD_FILE)\n",
    "\n",
    "# 此時dataset中的一個元素是(image, label0, label1, label2, label3)\n",
    "dataset = dataset.map(read_and_decode)\n",
    "dataset = dataset.shuffle(buffer_size=2000).batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定義神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alexnet_v2_captcha_multi(inputs,\n",
    "                             num_classes=10,\n",
    "                             is_training=True,\n",
    "                             dropout_keep_prob=0.5,\n",
    "                             spatial_squeeze=True,\n",
    "                             scope_name='alexnet_v2_captcha_multi',\n",
    "                             global_pool=False):\n",
    "    '''\n",
    "    參考 tensorflow github source code，改成 multi task learning\n",
    "    '''\n",
    "    with tf.variable_scope(scope_name) as sc:\n",
    "        net = slim.conv2d(inputs, 64, [11, 11], 4, padding='VALID', scope='conv1')\n",
    "        net = slim.max_pool2d(net, [3, 3], 2, scope='pool1')   \n",
    "        net = slim.conv2d(net, 192, [5, 5], scope='conv2')\n",
    "        net = slim.max_pool2d(net, [3, 3], 2, scope='pool2')\n",
    "        net = slim.conv2d(net, 384, [3, 3], scope='conv3')\n",
    "        net = slim.conv2d(net, 384, [3, 3], scope='conv4')\n",
    "        net = slim.conv2d(net, 256, [3, 3], scope='conv5')\n",
    "        net = slim.max_pool2d(net, [3, 3], 2, scope='pool5')\n",
    "\n",
    "        with slim.arg_scope([slim.conv2d],\n",
    "                            weights_initializer=tf.truncated_normal_initializer(0.0, 0.005),\n",
    "                            weights_regularizer=slim.l2_regularizer(0.0005),\n",
    "                            biases_initializer=tf.constant_initializer(0.1)):\n",
    "            net = slim.conv2d(net, 4096, [5, 5], padding='VALID', scope='fc6')\n",
    "            net = slim.dropout(net, dropout_keep_prob, is_training=is_training, scope='dropout6')\n",
    "            net = slim.conv2d(net, 4096, [1, 1], scope='fc7')\n",
    "            net = slim.dropout(net, dropout_keep_prob, is_training=is_training, scope='dropout7')\n",
    "\n",
    "            if num_classes:\n",
    "\n",
    "                net0 = slim.conv2d(net, num_classes, [1, 1],\n",
    "                                   activation_fn=None,\n",
    "                                   normalizer_fn=None,\n",
    "                                   biases_initializer=tf.zeros_initializer(),\n",
    "                                   scope='fc8_0')\n",
    "\n",
    "                net1 = slim.conv2d(net, num_classes, [1,1],\n",
    "                                   activation_fn=None,\n",
    "                                   normalizer_fn=None,\n",
    "                                   biases_initializer=tf.zeros_initializer(),\n",
    "                                   scope='fc8_1')\n",
    "\n",
    "                net2 = slim.conv2d(net, num_classes, [1,1],\n",
    "                                   activation_fn=None,\n",
    "                                   normalizer_fn=None,\n",
    "                                   biases_initializer=tf.zeros_initializer(),\n",
    "                                   scope='fc8_2')\n",
    "\n",
    "                net3 = slim.conv2d(net, num_classes, [1,1],\n",
    "                                   activation_fn=None,\n",
    "                                   normalizer_fn=None,\n",
    "                                   biases_initializer=tf.zeros_initializer(),\n",
    "                                   scope='fc8_3')\n",
    "\n",
    "            # 壓縮維度 4D to 2D，[batch, 1, 1, 10] to [batch, 10]\n",
    "            if spatial_squeeze:\n",
    "                net0 = tf.squeeze(net0, [1, 2], name='fc8_0/squeezed')\n",
    "                net1 = tf.squeeze(net1, [1, 2], name='fc8_1/squeezed')\n",
    "                net2 = tf.squeeze(net2, [1, 2], name='fc8_2/squeezed')\n",
    "                net3 = tf.squeeze(net3, [1, 2], name='fc8_3/squeezed')\n",
    "    return net0, net1, net2, net3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 定義網路變數\n",
    "x = tf.placeholder(tf.float32, [None, 224, 224])\n",
    "y0 = tf.placeholder(tf.float32, [None])\n",
    "y1 = tf.placeholder(tf.float32, [None])\n",
    "y2 = tf.placeholder(tf.float32, [None])\n",
    "y3 = tf.placeholder(tf.float32, [None])\n",
    "lr = tf.Variable(LEARNING_RATE, dtype=tf.float32)\n",
    "\n",
    "X = tf.reshape(x, [BATCH_SIZE, 224, 224, 1])\n",
    "logits0, logits1, logits2, logits3 = alexnet_v2_captcha_multi(X)\n",
    "\n",
    "one_hot_label0 = tf.one_hot(indices=tf.cast(y0,tf.int32), depth=CHAR_SET_LEN)\n",
    "one_hot_label1 = tf.one_hot(indices=tf.cast(y1,tf.int32), depth=CHAR_SET_LEN)\n",
    "one_hot_label2 = tf.one_hot(indices=tf.cast(y2,tf.int32), depth=CHAR_SET_LEN)\n",
    "one_hot_label3 = tf.one_hot(indices=tf.cast(y3,tf.int32), depth=CHAR_SET_LEN)\n",
    "\n",
    "loss0 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=one_hot_label0, logits=logits0))\n",
    "loss1 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=one_hot_label1, logits=logits1))\n",
    "loss2 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=one_hot_label2, logits=logits2))\n",
    "loss3 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=one_hot_label3, logits=logits3))\n",
    "\n",
    "total_loss = (loss0 + loss1 + loss2 + loss3) / 4.0\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=lr).minimize(total_loss)\n",
    "\n",
    "# 計算準確率\n",
    "y_pred0 = tf.nn.softmax(logits0)\n",
    "correct_pre0 = tf.equal(tf.argmax(one_hot_label0, 1), tf.argmax(y_pred0, 1))\n",
    "accuracy0 = tf.reduce_mean(tf.cast(correct_pre0, tf.float32))\n",
    "\n",
    "y_pred1 = tf.nn.softmax(logits1)\n",
    "correct_pre1 = tf.equal(tf.argmax(one_hot_label1, 1), tf.argmax(y_pred1, 1))\n",
    "accuracy1 = tf.reduce_mean(tf.cast(correct_pre1, tf.float32))\n",
    "\n",
    "y_pred2 = tf.nn.softmax(logits2)\n",
    "correct_pre2 = tf.equal(tf.argmax(one_hot_label2, 1), tf.argmax(y_pred2, 1))\n",
    "accuracy2 = tf.reduce_mean(tf.cast(correct_pre2, tf.float32))\n",
    "\n",
    "y_pred3 = tf.nn.softmax(logits3)\n",
    "correct_pre3 = tf.equal(tf.argmax(one_hot_label3, 1), tf.argmax(y_pred3, 1))\n",
    "accuracy3 = tf.reduce_mean(tf.cast(correct_pre3, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 檢測 next_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    b_image, b_label0, b_label1, b_label2, b_label3 = sess.run(next_element)\n",
    "    print(b_image.shape)\n",
    "    plt.imshow(b_image[0], cmap='gray')\n",
    "    print(b_label0[0], b_label1[0], b_label2[0], b_label3[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 開始訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter('captcha/TensorBoard/', graph = sess.graph)\n",
    "    \n",
    "    for i in range(TOTAL_STEPS):\n",
    "        b_image, b_label0, b_label1, b_label2, b_label3 = sess.run(next_element)       \n",
    "        sess.run(train_op, feed_dict={x:b_image, y0:b_label0, y1:b_label1, y2:b_label2, y3:b_label3})\n",
    "            \n",
    "        if i % 500 == 0 and i > 0:\n",
    "            sess.run(tf.assign(lr, lr * 0.5))\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            acc0, acc1, acc2, acc3, loss_ = sess.run([accuracy0, accuracy1, accuracy2, accuracy3, total_loss],\n",
    "                                                     feed_dict={x:b_image,\n",
    "                                                               y0:b_label0,\n",
    "                                                               y1:b_label1,\n",
    "                                                               y2:b_label2,\n",
    "                                                               y3:b_label3})\n",
    "            learning_rate = sess.run(lr)\n",
    "            print(\"Iter:%d/%d ,  Loss:%.3f  Accuracy:%.2f,%.2f,%.2f,%.2f  Learning_rate:%.5f\" % (\n",
    "                i, TOTAL_STEPS, loss_, acc0, acc1, acc2, acc3, learning_rate))\n",
    "\n",
    "        if acc0 > 0.90 and acc1 > 0.90 and acc2 > 0.90 and acc3 > 0.90:\n",
    "            saver.save(sess,'captcha/model/crack_captcha.model', global_step=i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
